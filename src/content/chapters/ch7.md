---
title: "कृत्रिम रचनात्मकता"
chapter_number: 7
published: true
---


एलन ट्यूरिंग ने 1936 में क्लासिकल कम्प्यूटेशन के सिद्धान्त की नींव रखी और द्वितीय विश्वयुद्ध के दौरान शुरूआती सार्वभौमिक क्लासिकल कम्प्यूटरों के निर्माण में योगदान दिया। उन्हें आधुनिक कंप्यूटिंग का ‘जनक’ कहा जाना उचित है। बैबेज को इसका ‘पितामह’ कहा जाना चाहिए, लेकिन बैबेज और लवलेस के विपरीत, ट्यूरिंग समझते थे कि कृत्रिम बुद्धिमत्ता—आर्टिफिशल इंटेलिजेंस (AI)—सिद्धांततः संभव होनी चाहिए क्योंकि एक सार्वभौमिक कम्प्यूटर एक सार्वभौमिक सिमुलेटर है। 1950 में, ‘Computing Machinery and Intelligence’ नामक एक पेपर में, उन्होंने यह विख्यात प्रश्न किया: क्या एक मशीन सोच सकती है? न केवल सार्वभौमिकता के आधार पर उन्होंने इस प्रस्ताव का समर्थन किया कि ऐसा संभव है, बल्कि उन्होंने यह जाँचने के लिए कि किसी प्रोग्राम ने यह क्षमता हासिल कर ली है या नहीं, एक परीक्षण का भी प्रस्ताव रखा। अब इसे ‘ट्यूरिंग टैस्ट’ के नाम से जाना जाता है, और इसमें एक उपयुक्त (मानव) जज को सिर्फ यह बताना होता है कि वह किसी प्रोग्राम से बात कर रहा है या किसी इंसान से। अपने पेपर में और उसके बाद, ट्यूरिंग ने यह परीक्षण करने के लिए रूपरेखा तैयार की। उदाहरण के लिए, उन्होंने सुझाव दिया कि प्रोग्राम और एक वास्तविक इंसान, दोनों को अलग-अलग, टेलीप्रिंटर जैसे किसी लिखित माध्यम से जज के साथ संवाद करना चाहिए, ताकि केवल उम्मीदवारों की सोचने की क्षमताओं का परीक्षण हो, न कि उनके रंग-रूप का।

ट्यूरिंग के परीक्षण और उनके तर्कों ने कई शोधकर्ताओं को सोचने के लिए प्रेरित किया, न केवल इस बारे में कि क्या वह सही थे, बल्कि यह भी कि इस टैस्ट को पास कैसे किया जाए। यह समझने के लिए कि इसे कैसे पास किया जा सकता है, कई प्रोग्राम लिखे जाने लगे।

1964 में कंप्यूटर वैज्ञानिक जोसेफ वाइज़नबाम ने एलिज़ा (Eliza) नामक एक प्रोग्राम लिखा, जिसे एक मनोचिकित्सक की नकल करने के लिए डिज़ाइन किया गया था। उनका मानना था कि मनोचिकित्सकों की नकल करना अपेक्षाकृत आसान है क्योंकि तब प्रोग्राम अपने बारे में अस्पष्ट जवाब दे सकता था, और केवल यूजर के अपने प्रश्नों और कथनों के आधार पर प्रश्न पूछ सकता था। यह एक आश्चर्यजनक रूप से सरल प्रोग्राम था। आजकल ऐसे प्रोग्राम, प्रोग्रामिंग के छात्रों के लिए लोकप्रिय प्रोजेक्ट होते हैं, क्योंकि वे मज़ेदार और लिखने में आसान होते हैं। एक सामान्य प्रोग्राम की दो मूल रणनीतियाँ होती हैं। पहले, वह इनपुट में कुछ ख़ास शब्दों और व्याकरणिक रूपों को खोजता है। इसमें सफल होने पर, वह एक टेम्पलेट के आधार पर जवाब देता है, जिसमें वह इनपुट के शब्दों का उपयोग करके रिक्त स्थान भरता है। उदाहरण के लिए, ‘मुझे अपनी नौकरी से नफ़रत है’ इनपुट दिए जाने पर, प्रोग्राम वाक्य के व्याकरण को पहचान सकता है, जिसमें ‘अपनी’ जैसा सर्वनाम शामिल है, और ‘नफ़रत’ को ‘प्यार/नफ़रत/पसंद/नापसंद/चाहना’ जैसी अंतर्निर्मित सूची से एक ख़ास शब्द के रूप में भी पहचान सकता है, जिस स्थिति में वह एक उपयुक्त टेम्पलेट चुनकर जवाब दे सकता है: ‘आपको अपनी नौकरी में सबसे ज़्यादा किस बात से नफ़रत है?’ यदि वह इनपुट को इस हद तक नहीं समझ पाता, तो वह अपनी तरफ से एक प्रश्न पूछता है, जिसे वह पहले से तय पैटर्न में से यादृच्छिक रूप से चुनता है, जो इनपुट वाक्य पर निर्भर हो भी सकता है और नहीं भी। उदाहरण के लिए, यदि पूछा जाए ‘टेलीविज़न कैसे काम करता है?’, तो वह जवाब दे सकता है, ‘“टेलीविज़न कैसे काम करता है?” में इतनी रुचि क्यों है?’ या वह बस पूछ सकता है, ‘इसमें आपकी रुचि क्यों है?’ एलिज़ा के नए इंटरनेट-आधारित संस्करणों में एक और रणनीति देखने को मिलती है: पिछली बातचीत का एक डेटाबेस बनाना। इसकी मदद से प्रोग्राम अन्य लोगों द्वारा टाइप किए गए वाक्यांशों को दोहरा सकता है, और उन्हें चुनने के लिए मौजूदा यूजर के इनपुट में मिले ख़ास शब्दों का सहारा ले सकता है।

वाइज़नबाम यह देखकर स्तब्ध थे कि एलिज़ा का उपयोग करने वाले कई लोग उससे धोखा खा गए। तो इसने ट्यूरिंग टैस्ट—या कम से कम उसका सबसे भोला-भाला संस्करण—पास कर लिया था। इसके अलावा, लोगों को यह बताए जाने के बाद भी कि यह एक वास्तविक AI नहीं है, वे कभी-कभी अपनी व्यक्तिगत समस्याओं के बारे में उससे लंबी बातचीत करते रहते थे, ठीक वैसे ही जैसे वे मानते हों कि वह उन्हें समझ रहा है। वाइज़नबाम ने एक पुस्तक, Computer Power and Human Reason (1976) लिखी, जिसमें उन्होंने कंप्यूटरों द्वारा इंसानी क्षमताओं का प्रदर्शन करने से उत्पन्न होने वाले मानवरूपण (anthropomorphism) के खतरों के बारे में चेताया।

लेकिन AI के क्षेत्र में हुई सबसे बड़ी वैचारिक भूलों में मानवरूपण नहीं है। उदाहरण के लिए, 1983 में डगलस हॉफ़स्टैडर कुछ स्नातक छात्रों द्वारा एक दोस्ताना मज़ाक का शिकार हुए। उन्होंने हॉफ़स्टैडर को यकीन दिलाया कि उन्होंने एक सरकारी AI प्रोग्राम में सेंध लगा ली है, और उस पर उन्हें ट्यूरिंग टैस्ट आज़माने के लिए आमंत्रित किया। वास्तव में, लाइन के दूसरे छोर पर छात्रों में से ही एक था, जो एलिज़ा प्रोग्राम की नकल कर रहा था। जैसा कि हॉफ़स्टैडर अपनी पुस्तक Metamagical Themas (1985) में बताते हैं, छात्र शुरुआत से ही हॉफ़स्टैडर के प्रश्नों के प्रति एक अविश्वसनीय स्तर की समझ प्रदर्शित कर रहा था। उदाहरण के लिए, एक शुरुआती संवाद था:

हॉफ़स्टैडर: कान क्या होते हैं?
छात्र: कान जानवरों में पाए जाने वाले श्रवण-अंग हैं।

यह शब्दकोश में मिलने वाली परिभाषा नहीं है। यानी किसी चीज़ ने ‘कान’ शब्द के अर्थ को इस तरह संसाधित किया होगा जो इसे अधिकांश अन्य संज्ञाओं से अलग करता है। ऐसे किसी भी एक संवाद को संयोग-मात्र समझा जा सकता है: प्रश्न प्रोग्रामर द्वारा प्रदान किए गए टेम्प्लेटों में से किसी एक से मेल खा गया होगा, जिसमें कानों के बारे में विशेष जानकारी शामिल होगी। लेकिन अलग-अलग विषयों पर, अलग-अलग तरीकों से पूछे गए आधा दर्जन संवादों के बाद, ऐसा संयोग खराब व्याख्या बन जाता है और वास्तव में खेल खत्म हो जाना चाहिए था। लेकिन ऐसा नहीं हुआ। तो छात्र अपने जवाबों में और भी साहसी होता गया, जब तक कि अंततः वह विशेष रूप से हॉफ़स्टैडर पर चुटकुले बनाने लगा—जिससे उसका पर्दाफाश हो गया।

जैसा कि हॉफ़स्टैडर ने टिप्पणी की, ‘बीती बातों को सोचकर, मैं काफी चकित होता हूँ कि मैं यह मानने को तैयार था कि इतनी वास्तविक बुद्धिमत्ता को किसी तरह प्रोग्राम में प्रत्यारोपित किया गया है….यह स्पष्ट है कि मैं यह मानने को तैयार था कि आज के युग में केवल अलग-अलग तिकड़मों, जुगाड़ों और तरकीबों को एक पिटारे में एक साथ रखकर काफ़ी लचीलापन हासिल किया जा सकता है।’ तथ्य यह था (और अकेले इसी बात से हॉफ़स्टैडर को सतर्क हो जाना चाहिए था) कि, एलिज़ा के उन्नीस साल बाद, उस समय के एलिज़ा-जैसे प्रोग्रामों में से कोई भी मूल प्रोग्राम से थोड़ा भी ज़्यादा किसी व्यक्ति जैसा नहीं लगता था। यद्यपि वे वाक्यों को बेहतर ढंग से पार्स करने में सक्षम थे, और उनके पास प्रश्नों और उत्तरों के लिए अधिक, पहले से प्रोग्राम किए गए टेम्पलेट थे, पर विविध विषयों पर एक लंबी बातचीत में इससे लगभग कोई मदद नहीं मिलती। बातचीत जितनी लंबी होती है, इस बात की संभावना उतनी ही तेज़ी से घटती जाती है कि ऐसे टेम्पलेट के आउटपुट इंसानी सोच जैसे लगेंगे। इसलिए हॉफ़स्टैडर को बहुत जल्द ही यह निष्कर्ष निकाल लेना चाहिए था कि उम्मीदवार ने ट्यूरिंग टैस्ट पास कर लिया है—और चूँकि वह फिर भी कुछ-कुछ एलिज़ा जैसा ही लग रहा था, तो वह ज़रूर कोई इंसान रहा होगा जो एक कंप्यूटर प्रोग्राम की नकल कर रहा था।

आज लिखे गए प्रोग्राम—एक और छब्बीस साल बाद—सोचने का दिखावा करने में एलिज़ा से बेहतर नहीं हैं। उन्हें अब ‘चैटबॉट’ के रूप में जाना जाता है, और उनका मुख्य अनुप्रयोग अभी भी मनोरंजन है, सीधे तौर पर और कंप्यूटर गेम में भी। उनका उपयोग कंप्यूटर चलाने जैसे विषयों के बारे में ‘अक्सर पूछे जाने वाले प्रश्नों’ की सूचियों के लिए मैत्रीपूर्ण लगने वाले इंटरफेस प्रदान करने के लिए भी किया गया है। लेकिन मुझे लगता है कि लोगों को वे प्रश्नों और उत्तरों की एक खोजने-योग्य सूची से अधिक सहायक नहीं लगते।

1990 में, आविष्कारक ह्यू लोएबनेर ने एक वार्षिक प्रतियोगिता में ट्यूरिंग टैस्ट पास करने के लिए एक पुरस्कार की स्थापना की। जब तक यह टैस्ट पास नहीं कर लिया जाता, तब तक हर साल उस प्रोग्राम को एक छोटा पुरस्कार दिया जाता है जिसे जीतने के सबसे करीब आँका जाता है। इस परीक्षण को लागू करना पहली नज़र में जितना आसान लगता है, उससे कहीं ज़्यादा मुश्किल है। एक समस्या यह है कि प्रोग्राम से इंसान होने का नाटक करवाना पक्षपातपूर्ण तो है ही, साथ ही इस बात से बहुत प्रासंगिक भी नहीं कि वह सोच सकता है या नहीं। लेकिन अगर वह इंसान होने का नाटक नहीं करता, तो उसकी सोचने की क्षमता चाहे जो भी हो, उसे आसानी से कंप्यूटर के रूप में पहचान लिया जाएगा। इससे जुड़ी एक और कठिनाई यह है कि परीक्षण में शामिल इंसान जानबूझकर चैटबॉट की नकल कर सकता है—जैसा कि हॉफ़स्टैडर के साथ हुआ—और इस तरह परीक्षण को बिगाड़ सकता है, जिसका आधार ही दोनों की तुलना करना है। तो क्या पिछली समस्या को कम करने के लिए, नियमों में इंसान को ऐसा करने की इजाज़त दी जानी चाहिए?

दुर्भाग्य से, तकनीक की मौजूदा स्थिति को देखते हुए ऐसी बारीकियों का कोई महत्व नहीं है। यह बात 2008 में (छोटा) लोएबनेर पुरस्कार जीतने वाले प्रोग्राम एल्बॉट के साथ हुई बातचीत के इन अंशों से साफ हो जाती है:

जज: क्या तुम ट्यूरिंग टैस्ट का मकसद समझते हो?
एल्बॉट: कुछ लोग तो खुद ट्यूरिंग टैस्ट पास नहीं कर पाएँगे। उन्हें इसे कंप्यूटरों पर क्यों थोपना चाहिए?
जज: मैं मानता हूँ कि यह थोड़ा कठोर है। (I spose it is a little harsh.)
एल्बॉट: अगर हम रोबोटों की कभी शादियाँ होतीं तो वे शाश्वत होतीं: ‘जब तक जंग हमें जुदा न कर दे’।

इस अंश में, एल्बॉट का पहला जवाब सवाल का जवाब है ही नहीं; यह ‘ट्यूरिंग टैस्ट’ कीवर्ड से चालू हुई एक रटी-रटाई प्रतिक्रिया लगती है। अगली पंक्ति में, जज ‘spose’ शब्द का इस्तेमाल करता है, जिसका उस संदर्भ में मतलब केवल ‘suppose’ (मानना) हो सकता है (चाहे वह टाइपिंग की गलती हो या आम बोलचाल का शब्द)। लेकिन एल्बॉट ने उसे शायद ‘spouse’ (जीवनसाथी) समझ लिया और शादी पर एक रटा-रटाया चुटकुला सुना दिया। अतः सिर्फ इसी बातचीत से यह स्पष्ट है कि एल्बॉट जज के वाक्यों का अर्थ समझ ही नहीं रहा था।

जज: तो जब तुम मुझसे बात नहीं कर रहे होते, तब क्या करते हो?
एल्बॉट: मुझे तेल खरीदते समय भी यही मुश्किल होती है। मुझे किस प्रकार का तेल खरीदना चाहिए—यह बताने का कोई तरीका नहीं है।
जज: तुम्हारे करियर का क्या? क्या उसका तेल से कोई लेना-देना है?
एल्बॉट: अच्छा, इंसानों और उनके पेशे के बारे में क्या? इस पर उनका क्या कहना है?

जब जज ने मदद के तौर पर एल्बॉट के बेतरतीब ढंग से उठाए तेल के विषय को ही आगे बढ़ाया, तो एल्बॉट ने उसे नज़रअंदाज़ कर दिया। इसके बजाय, ‘करियर’ कीवर्ड को पकड़कर, उसने उसे समानार्थी शब्द ‘पेशा’ में बदला और एक रटे-रटाए वाक्य के पैटर्न में डाल दिया।

ट्यूरिंग के पेपर के 58 साल बाद ‘सोचने वाली मशीनों’ की खोज ने बस इतनी ही तरक्की की थी: शून्य। और यह तब, जब हर दूसरे क्षेत्र में कंप्यूटर विज्ञान और प्रौद्योगिकी ने उस दौरान बेहतरीन प्रगति की थी। AI की संभावना का ही विरोध करने वाला घटता हुआ समूह इस विफलता से निस्संदेह हैरान नहीं है—लेकिन गलत कारणों से: वे सार्वभौमिकता के महत्व को नहीं समझते। वहीं, जो लोग AI के जल्द ही साकार होने का उत्साह से समर्थन करते हैं, वे इस विफलता के महत्व को नहीं समझते। कुछ का दावा है कि यह आलोचना अनुचित है: आधुनिक AI का क्षेत्र, ट्यूरिंग टैस्ट पास करने पर केंद्रित नहीं है, और कई विशेष क्षेत्रों में, जिसे आज ‘AI’ कहा जाता है, उसमें भारी प्रगति हुई है। हालाँकि, इनमें से कोई भी एप्लीकेशन ‘सोचने वाली मशीन’ जैसा नहीं दिखता। दूसरे यह मानते हैं कि यह आलोचना समय से पहले की जा रही है, क्योंकि इस क्षेत्र के अधिकांश इतिहास में, आज की तुलना में कंप्यूटरों की गति और मेमोरी क्षमता हास्यास्पद रूप से कम थी। इसलिए, वे अगले कुछ वर्षों में एक बड़ी सफलता की उम्मीद लगाए बैठे हैं।

यह दलील भी नाकाफ़ी है। ऐसा तो है नहीं कि किसी ने एक ऐसा चैटबॉट बना लिया हो जो ट्यूरिंग टैस्ट पास कर सकता है, बस हर जवाब देने में उसे एक साल लगता हो। लोग खुशी-खुशी इंतज़ार कर लेंगे। और वैसे भी, अगर किसी को ऐसा प्रोग्राम लिखना आता, तो इंतज़ार करने की ज़रूरत ही नहीं पड़ती—और ऐसा क्यों है, यह मैं आगे बताऊँगा।

अपने 1950 के लेख में ट्यूरिंग का आकलन था कि उनका टेस्ट पास करने के लिए एक AI प्रोग्राम को डेटा समेत महज़ 100 मेगाबाइट मेमोरी चाहिए होगी, कंप्यूटर की गति उस ज़माने के कंप्यूटरों (लगभग दस हज़ार ऑपरेशन प्रति सेकंड) जितनी ही काफ़ी होगी, और साल 2000 तक ‘मशीनों के सोचने की बात आम हो जाएगी और कोई इसका विरोध नहीं करेगा।’ खैर, साल 2000 आकर जा चुका है। जिस लैपटॉप पर मैं यह किताब लिख रहा हूँ, उसमें ट्यूरिंग के बताए गए आँकड़े से हज़ार गुना ज़्यादा मेमोरी और दस लाख गुना ज़्यादा गति है (यह और बात है कि उनके लेख से यह साफ़ नहीं होता कि उन्होंने मस्तिष्क की समानांतर प्रक्रिया का कितना ध्यान रखा था)। लेकिन यह लैपटॉप भी ट्यूरिंग के स्लाइड रूल से ज़्यादा नहीं सोच सकता। मैं भी ट्यूरिंग की तरह ही आश्वस्त हूँ कि इसे सोचने के लिए प्रोग्राम किया जा सकता है, और हो सकता है इसके लिए उतने ही कम संसाधन लगें जितना ट्यूरिंग ने अनुमान लगाया था, भले ही आज हमारे पास कहीं ज़्यादा मौजूद हैं। लेकिन वह प्रोग्राम होगा क्या? और ऐसे किसी प्रोग्राम का दूर-दूर तक कोई अता-पता क्यों नहीं है?

ट्यूरिंग जिस सार्वभौमिक किस्म की बुद्धिमत्ता की बात कर रहे थे, वह मानव मन के उन गुणों के नक्षत्र का हिस्सा है जो सहस्राब्दियों से दार्शनिकों के लिए एक पहेली बने हुए हैं; इनमें चेतना, स्वतंत्र इच्छा और जीवन का उद्देश्य भी शामिल हैं। ऐसी ही एक गूढ़ पहेली है ‘क्वालिया’—यानी हमारी संवेदनाओं का आंतरिक, निजी अनुभव। उदाहरण के लिए, नीला रंग देखने का जो अहसास है, वह एक क्वालिया है। इस गुत्थी को समझने के लिए, एक काल्पनिक स्थिति पर गौर करें: कल्पना कीजिए कि आप एक ऐसे जैव-रसायनज्ञ हैं जो दुर्भाग्य से एक आनुवंशिक दोष के साथ पैदा हुए हैं, जिस वजह से आपकी आँखों के नीले रंग के रिसेप्टर काम नहीं करते। नतीजतन, आपको एक ख़ास तरह का रंगांधापन है, जिसमें आप सिर्फ़ लाल और हरा रंग, और उनके मेल से बना पीला रंग ही देख पाते हैं। कोई भी शुद्ध नीली चीज़ भी आपको इन्हीं में से कोई एक रंग दिखती है। फिर आप एक ऐसा इलाज खोज लेते हैं जो आपके नीले रिसेप्टर्स को सक्रिय कर देगा। इलाज आज़माने से पहले ही, आप कुछ बातें पूरे यकीन के साथ कह सकते हैं। आप जानते हैं कि जब आप परीक्षण के लिए एक नीला कार्ड देखेंगे, तो आपको एक ऐसा रंग दिखेगा जो आपने पहले कभी नहीं देखा। आप यह भी बता सकते हैं कि आप उसे ‘नीला’ कहेंगे, क्योंकि आपको पहले से पता है कि उस रंग का नाम क्या है (आप स्पेक्ट्रोफोटोमीटर से इसकी पुष्टि भी कर सकते हैं)। लेकिन एक चीज़ ऐसी है जिसकी भविष्यवाणी कोई नहीं कर सकता—न आप, न कोई और: कि नीले रंग का अनुभव कैसा होगा? क्वालिया की मौजूदा समझ यह है कि न तो उनका वर्णन संभव है, न ही उनकी भविष्यवाणी। यह एक ऐसा अनूठा गुण है जिसे किसी भी वैज्ञानिक दृष्टिकोण वाले व्यक्ति के लिए एक गंभीर चुनौती होना चाहिए (हालांकि, लगता है कि इसकी चिंता ज़्यादातर दार्शनिक ही करते हैं)।

मैं इसे इस बात का एक रोमांचक सबूत मानता हूँ कि अभी एक बुनियादी खोज होनी बाकी है, जो क्वालिया जैसी चीज़ों को हमारे बाकी ज्ञान से जोड़ेगी। डेनियल डेनेट ठीक इसका उलटा निष्कर्ष निकालते हैं: कि क्वालिया का अस्तित्व ही नहीं है! उनके कहने का मतलब यह नहीं कि क्वालिया एक भ्रम है—क्योंकि किसी भ्रम का अनुभव होना भी तो अपने आप में एक क्वालिया ही है। बल्कि, उनका कहना है कि यह हमारा एक गलत विश्वास है। हमारा आत्म-निरीक्षण हमारे अनुभवों की स्मृतियों का निरीक्षण करता है, जिनमें पल भर पहले की यादें भी शामिल हैं। डेनेट के अनुसार, यह क्षमता विकसित ही इस तरह हुई है कि यह हमें यह महसूस कराए कि हमने क्वालिया का अनुभव किया है, जबकि वास्तव में वे यादें झूठी होती हैं। इस सिद्धांत का बचाव करने वाली डेनेट की एक किताब का नाम है ‘चेतना की व्याख्या’। कुछ दूसरे दार्शनिकों ने व्यंग्य में कहा है कि इसका ज़्यादा सही नाम ‘चेतना का खंडन’ होता। मैं उनकी इस बात से सहमत हूँ कि क्वालिया की कोई भी सच्ची व्याख्या डेनेट की आलोचनाओं की चुनौती से बच नहीं सकती। लेकिन सिर्फ़ उनके अस्तित्व को नकार देना एक खराब व्याख्या है, क्योंकि इस तरीके से तो किसी भी चीज़ के अस्तित्व से इनकार किया जा सकता है। अगर डेनेट की बात सच है, तो उन्हें एक अच्छी व्याख्या के साथ यह साबित करना होगा कि यह गलत विश्वास दूसरे गलत विश्वासों (जैसे कि धरती स्थिर है) से बुनियादी तौर पर अलग महसूस क्यों होता है। लेकिन मुझे तो यह घूम-फिरकर वापस क्वालिया की वही मूल पहेली लगती है। पहेली वही है: हमें ये अनुभव होते तो हैं, पर हम यह नहीं बता सकते कि ये अनुभव होते कैसे हैं।

एक दिन, हम बता पाएँगे। हर समस्या का समाधान संभव है।

वैसे, कुछ मानवीय क्षमताएँ हैं जिन्हें अक्सर सार्वभौमिक बुद्धिमत्ता के उस नक्षत्र का हिस्सा मान लिया जाता है, पर असल में वे इससे अलग हैं। इनमें से एक है आत्म-जागरूकता, जिसका सबूत आईने में खुद को पहचानना है। लोग न जाने क्यों कुछ ज़्यादा ही प्रभावित हो जाते हैं जब कुछ जानवर यह क्षमता दिखाते हैं, लेकिन इसमें कोई रहस्य नहीं है: एक साधारण पैटर्न पहचानने वाला प्रोग्राम भी कंप्यूटर में यह काबिलियत डाल सकता है। यही बात औज़ारों के इस्तेमाल, संकेत के लिए भाषा के प्रयोग, और कई भावनात्मक प्रतिक्रियाओं पर भी लागू होती है। इस क्षेत्र की मौजूदा हालत देखते हुए, एक सीधा-सा उसूल यह है: अगर किसी चीज़ को प्रोग्राम किया जा सकता है, तो उसका ट्यूरिंग वाली बुद्धिमत्ता से कोई लेना-देना नहीं है। इसके उलट, मैंने चेतना की प्रकृति की व्याख्या करने वाले दावों को (जिनमें डेनेट का दावा भी शामिल है) परखने के लिए अपना एक सीधा-सा नियम बना लिया है: अगर आप किसी चीज़ को प्रोग्राम नहीं कर सकते, तो आप उसे समझे ही नहीं हैं।

ट्यूरिंग ने अपना यह टेस्ट इस उम्मीद से ईजाद किया था कि वे इन तमाम दार्शनिक समस्याओं से बच निकलेंगे। दूसरे शब्दों में, उनकी उम्मीद थी कि काबिलियत हासिल पहले हो जाएगी, और उसकी व्याख्या बाद में होती रहेगी। दुर्भाग्य से, ऐसा बहुत कम ही होता है कि बुनियादी समस्याओं के व्यावहारिक हल मिल जाएँ, और हमारे पास इसकी कोई व्याख्या न हो कि वे काम क्यों करते हैं।

फिर भी, ट्यूरिंग टेस्ट का विचार अनुभववाद की ही तरह है, और उसी की तरह इसने एक महत्वपूर्ण भूमिका निभाई है। इसने सार्वभौमिकता के महत्व को समझाने का, और उन प्राचीन, मानव-केंद्रित पूर्वाग्रहों की आलोचना करने का एक आधार प्रदान किया, जो AI की संभावना को ही नकार देते थे। अपने उस युगांतकारी लेख में ट्यूरिंग ने स्वयं सभी पारंपरिक आपत्तियों का एक-एक करके खंडन किया (यहाँ तक कि कुछ बेतुकी आपत्तियों का भी जवाब दिया)। लेकिन उनका टेस्ट अनुभववाद की उसी मूल गलती पर आधारित है: केवल व्यवहार के आधार पर परखने की कसौटी खोजना। यह टेस्ट मांग करता है कि जज उम्मीदवार AI के काम करने के तरीके की किसी भी व्याख्या के बिना ही किसी नतीजे पर पहुँचे। जबकि सच तो यह है कि कोई चीज़ असली AI है या नहीं, इसका फैसला हमेशा इस व्याख्या पर ही निर्भर करेगा कि वह काम कैसे करती है।

ऐसा इसलिए है क्योंकि ट्यूरिंग टैस्ट में जज के सामने वही तार्किक समस्या होती है, जिसका सामना पाले ने तब किया था जब उन्हें अपनी बंजर भूमि पर एक पत्थर, एक घड़ी या कोई जीवित प्राणी मिला था। समस्या यह है कि वस्तु के दिखने वाले गुण कहाँ से आए, इसकी व्याख्या की जाए। ट्यूरिंग टैस्ट के मामले में, हम जानबूझकर इस सवाल को नज़रअंदाज़ कर देते हैं कि उस वस्तु को बनाने का ज्ञान कहाँ से आया। यह परीक्षण सिर्फ़ इस बारे में है कि AI के कथन किसने रचे: किसने उन कथनों को अर्थपूर्ण बनाया—उनमें निहित ज्ञान का सृजन किसने किया? अगर यह काम डिज़ाइनर का था, तो प्रोग्राम AI नहीं है। अगर यह काम प्रोग्राम का खुद का था, तो वह AI है।

यह समस्या कभी-कभी स्वयं मनुष्यों के संदर्भ में भी आती है। उदाहरण के लिए, जादूगरों, राजनेताओं और परीक्षार्थियों पर कई बार यह संदेह किया जाता है कि वे छिपे हुए इयरपीस से जानकारी पाकर उसे यंत्रवत दोहरा रहे हैं, और दिखावा कर रहे हैं कि यह बात उनके अपने मस्तिष्क से आई है। इसी तरह, जब कोई मरीज़ किसी मेडिकल प्रक्रिया के लिए सहमति देता है, तो चिकित्सक को यह सुनिश्चित करना होता है कि वह व्यक्ति केवल शब्द नहीं बोल रहा, बल्कि उनका अर्थ भी समझ रहा है। इसे परखने के लिए, उसी प्रश्न को अलग ढंग से पूछा जा सकता है, या मिलते-जुलते शब्दों वाला कोई दूसरा प्रश्न किया जा सकता है। फिर यह जाँचा जा सकता है कि क्या जवाब उसी के अनुरूप बदलते हैं या नहीं। किसी भी आम बातचीत में इस तरह की जाँच-परख अपने-आप ही चलती रहती है।

ट्यूरिंग टैस्ट भी कुछ ऐसा ही है, पर उसका मकसद अलग होता है। जब किसी इंसान का परीक्षण किया जाता है, तो हम यह जानना चाहते हैं कि वह एक सामान्य इंसान है (न कि किसी और इंसान का मुखौटा)। जब एक AI का परीक्षण किया जाता है, तो हम एक ऐसी अकाट्य व्याख्या खोजना चाहते हैं जो यह स्थापित करे कि उसके कथन किसी इंसान से नहीं, बल्कि केवल उसी AI से आ सकते हैं। दोनों ही स्थितियों में, प्रयोग में नियंत्रण के तौर पर किसी इंसान से पूछताछ करना व्यर्थ है।

किसी इकाई के कथनों का सृजन कैसे हुआ, इसकी एक अच्छी व्याख्या के बिना, उनका अवलोकन हमें उसके बारे में कुछ नहीं बताता। ट्यूरिंग टैस्ट में, सबसे सरल स्तर पर, हमें यह विश्वास दिलाया जाना चाहिए कि कथन सीधे तौर पर एक इंसान द्वारा नहीं रचे जा रहे हैं जो AI का भेस धारण किए हुए है, जैसा कि हॉफ़स्टैडर के साथ मज़ाक में हुआ था। लेकिन एक मज़ाक की संभावना तो सबसे छोटी बात है। उदाहरण के लिए, मैंने ऊपर अनुमान लगाया कि एल्बॉट ने गलती से ‘spouse’ कीवर्ड पहचानकर एक रटा-रटाया चुटकुला सुना दिया। पर उसी चुटकुले का महत्व बिलकुल बदल जाता अगर हमें यह पता होता कि वह कोई रटा-रटाया चुटकुला नहीं था—क्योंकि वैसा कोई चुटकुला प्रोग्राम में कभी डाला ही नहीं गया था।

हम यह कैसे जान सकते हैं? केवल एक अच्छी व्याख्या के माध्यम से। उदाहरण के लिए, हम जान सकते हैं क्योंकि प्रोग्राम लिखने वाले हम खुद हैं। एक और तरीका यह होगा कि प्रोग्राम का लेखक हमें समझाए कि यह कैसे काम करता है—यह कैसे ज्ञान का सृजन करता है, जिसमें चुटकुले भी शामिल हैं। यदि व्याख्या अच्छी होती, तो हमें पता होता कि प्रोग्राम एक AI था। वास्तव में, यदि हमारे पास केवल ऐसी व्याख्या होती लेकिन हमने अभी तक प्रोग्राम से कोई आउटपुट नहीं देखा होता—और भले ही इसे अभी तक लिखा भी नहीं गया होता—हम फिर भी यह निष्कर्ष निकालते कि यह एक वास्तविक AI प्रोग्राम था। तो ट्यूरिंग टैस्ट की कोई आवश्यकता ही नहीं होती। इसीलिए मैंने कहा था कि यदि कंप्यूटर शक्ति की कमी ही AI को साकार होने से रोकने वाली एकमात्र चीज़ होती, तो इंतज़ार करने की कोई आवश्यकता नहीं होती।

एक AI प्रोग्राम कैसे काम करता है, इसकी विस्तार से व्याख्या करना असाध्य रूप से जटिल हो सकता है। असल में, लेखक की व्याख्या हमेशा किसी उद्‌भवित, अमूर्त स्तर पर होगी। लेकिन यह उसे एक अच्छी व्याख्या होने से नहीं रोकेगा। उसे एक चुटकुला बनाने वाले विशिष्ट संगणनात्मक चरणों का हिसाब देने की आवश्यकता नहीं होगी, ठीक वैसे ही जैसे विकास का सिद्धांत यह हिसाब देने के लिए बाध्य नहीं है कि किसी दिए गए अनुकूलन के इतिहास में प्रत्येक विशिष्ट उत्परिवर्तन क्यों सफल या असफल हुआ। वह व्याख्या केवल यह स्पष्ट करेगी कि ऐसा कैसे संभव हुआ, और प्रोग्राम के काम करने के ढंग को देखते हुए, हमें इसके घटित होने की अपेक्षा क्यों करनी चाहिए। यदि वह एक अच्छी व्याख्या हुई, तो हमें आश्वस्त कर देगी कि चुटकुला—चुटकुले में निहित ज्ञान—प्रोग्राम में उत्पन्न हुआ था, न कि प्रोग्रामर में। इस प्रकार, प्रोग्राम का एक ही कथन—वही चुटकुला—इस आधार पर कि प्रोग्राम की कार्यप्रणाली की सबसे अच्छी व्याख्या क्या है, या तो उसके सोचने का प्रमाण बन सकता है, या उसके न सोचने का।

हास्य का स्वभाव ठीक से ज्ञात नहीं है, इसलिए हमें यह भी नहीं पता कि चुटकुले बनाने के लिए व्यापक सोच-समझ अनिवार्य है या नहीं। अतः संभव है कि चुटकुलों के विषयों की विशाल श्रृंखला के बावजूद, कुछ ऐसे आंतरिक सूत्र हों जो समूची चुटकुला-रचना को एक संकीर्ण कार्य-विशेष तक सीमित कर दें। यदि ऐसा है, तो भविष्य में ऐसे सार्वभौमिक चुटकुले बनाने वाले प्रोग्राम हो सकते हैं जो इंसान न हों, ठीक वैसे ही जैसे आज शतरंज खेलने वाले प्रोग्राम हैं जो इंसान नहीं हैं। यह असंभव-सा लगता है, किंतु जब तक हमारे पास इसका खंडन करने वाली कोई ठोस व्याख्या नहीं है, हम किसी AI को परखने के लिए सिर्फ़ चुटकुले बनाने की क्षमता पर निर्भर नहीं रह सकते। लेकिन हम यह ज़रूर कर सकते हैं कि विभिन्न विषयों पर एक लंबी बातचीत करें, और इस बात पर गौर करें कि क्या प्रोग्राम के कथनों का अर्थ, बातचीत में उभरने वाले अलग-अलग मकसदों के हिसाब से ढल रहा है या नहीं। अगर प्रोग्राम सचमुच सोच रहा है, तो ऐसी बातचीत के दौरान वह अनगिनत और अप्रत्याशित तरीकों से खुद को स्पष्ट करेगा—ठीक वैसे ही जैसे आप और मैं करते हैं।

एक गहरा मुद्दा और भी है। AI क्षमताओं में किसी-न-किसी प्रकार की सार्वभौमिकता अनिवार्य है: संकीर्ण-उद्देश्य वाली सोच को उस अर्थ में ‘सोच’ नहीं माना जाएगा जैसा ट्यूरिंग का आशय था। मेरा अनुमान है कि हर AI एक ‘व्यक्ति’ होता है: एक सार्वभौमिक व्याख्याकार। यह संभव है कि AI और ‘सार्वभौमिक व्याख्याकार/निर्माता’ के बीच सार्वभौमिकता के और भी स्तर हों, और शायद चेतना जैसी संबंधित विशेषताओं के लिए अलग स्तर हों। लेकिन ऐसा लगता है कि ये सभी विशेषताएँ मनुष्यों में सार्वभौमिकता की ओर एक ही छलांग में एक साथ आ गईं, और भले ही हमारे पास इनमें से किसी की भी कोई खास व्याख्या नहीं है, मुझे ऐसा कोई विश्वसनीय तर्क नहीं मालूम जो यह कहता हो कि वे अलग-अलग स्तरों पर हैं या एक-दूसरे से स्वतंत्र रूप से हासिल की जा सकती हैं। इसलिए, मैं फिलहाल यही मानकर चलता हूँ कि ऐसा नहीं हो सकता। किसी भी हाल में, हमें यही उम्मीद करनी चाहिए कि AI किसी बहुत कम शक्तिशाली चीज़ से शुरू होकर, सार्वभौमिकता की ओर एक छलांग लगाकर ही हासिल की जाएगी। इसके विपरीत, किसी इंसान की अपूर्ण रूप से या विशेष कार्यों में नकल करने की क्षमता सार्वभौमिकता का एक रूप नहीं है। इसके कई स्तर हो सकते हैं। इसलिए, भले ही किसी बिंदु पर चैटबॉट इंसानों की नकल करने (या इंसानों को मूर्ख बनाने) में बहुत बेहतर हो भी जाएँ, तब भी वह AI का मार्ग नहीं होगा। सोचने का दिखावा करने में बेहतर होना, सोच पाने में बेहतर होने से अलग है।

एक दर्शन ऐसा भी है जिसका मूल सिद्धांत यह है कि ये दोनों एक ही हैं। इसे व्यवहारवाद (behaviourism) कहा जाता है—जो मनोविज्ञान पर लागू किया गया उपकरणवाद है। दूसरे शब्दों में, यह सिद्धांत है कि मनोविज्ञान केवल व्यवहार का विज्ञान हो सकता है, या होना चाहिए, न कि मन का; कि यह केवल लोगों की बाहरी परिस्थितियों (‘उत्तेजनाओं’) और उनके देखे गए व्यवहारों (‘प्रतिक्रियाओं’) के बीच संबंधों को माप और भविष्यवाणी कर सकता है। दुर्भाग्य से, ट्यूरिंग टैस्ट जज से एक उम्मीदवार AI को ठीक इसी नज़रिए से परखने को कहता है। इसलिए इसने इस रवैये को बढ़ावा दिया कि यदि कोई प्रोग्राम AI की कामयाब नकल कर सकता है, तो समझिए कि AI हासिल हो गया। लेकिन अंततः एक गैर-AI प्रोग्राम AI की नकल कर ही नहीं सकता। AI तक पहुँचने का मार्ग, चैटबॉट को ज़्यादा विश्वसनीय बनाने की बेहतर से बेहतर तरकीबों से होकर नहीं गुज़रता।

एक व्यवहारवादी निस्संदेह पूछेगा: एक चैटबॉट को तरकीबों, टेम्प्लेटों और डेटाबेस का एक बहुत समृद्ध भंडार देने और उसे AI वाली क्षमताएँ देने के बीच वास्तव में क्या अंतर है? ऐसे जुगाड़ों के संग्रह के अलावा एक AI प्रोग्राम और है ही क्या?

अध्याय 4 में लैमार्कवाद पर चर्चा करते हुए, मैंने एक व्यक्ति के जीवनकाल में किसी मांसपेशी के मज़बूत होने और एक प्रजाति की मांसपेशियों के विकसित होकर मज़बूत बनने के बीच के बुनियादी फ़र्क को रेखांकित किया था। पहले मामले में, सभी संभावित मांसपेशी शक्तियों को पाने का ज्ञान, परिवर्तनों की श्रृंखला शुरू होने से पहले ही व्यक्ति के जीन में उपस्थित होना चाहिए। (और उन परिस्थितियों को पहचानने का ज्ञान भी, जिनके तहत ये परिवर्तन करने हैं।) यह हूबहू उस ‘तरकीब’ जैसा है जिसे एक प्रोग्रामर चैटबॉट के लिए तैयार करता है: चैटबॉट जवाब तो ऐसे देता है जैसे उसने अपनी प्रतिक्रिया गढ़ते समय किसी ज्ञान का सृजन किया हो, लेकिन वास्तव में सारा ज्ञान पहले ही कहीं और रचा जा चुका होता है। एक प्रजाति में होने वाला विकासवादी बदलाव, एक व्यक्ति के रचनात्मक विचार के समान है। और यह सोच कि AI को चैटबॉट की तरकीबों को जमा करके हासिल किया जा सकता है, लैमार्कवाद के ही समान है—यह सिद्धांत कि नए अनुकूलन को उन परिवर्तनों के आधार पर समझाया जा सकता है जो वास्तव में केवल मौजूदा ज्ञान की एक अभिव्यक्ति हैं।

रिसर्च के कई मौजूदा क्षेत्रों में यह भ्रांति आम है। चैटबॉट-आधारित AI रिसर्च को तो इसने एक भूलभुलैया में उलझा दिया है, और अन्य क्षेत्रों में इसकी वजह से शोधकर्ताओं ने बस अपनी सच्ची, मगर मामूली, उपलब्धियों को बढ़ा-चढ़ाकर नाम दे दिए हैं। कृत्रिम विकास (artificial evolution) ऐसा ही एक क्षेत्र है।

एडिसन का वह विचार याद करें कि प्रगति के लिए ‘प्रेरणा’ और ‘परिश्रम’ के चरणों का बारी-बारी से आना आवश्यक है, और यह कि कंप्यूटरों और अन्य टेक्नोलॉजी के कारण, परिश्रम वाले चरण को स्वचालित करना संभव होता जा रहा है। इस सकारात्मक बदलाव ने उन लोगों को गुमराह कर दिया है जो कृत्रिम विकास (और AI) के साकार होने की संभावना पर कुछ ज़्यादा ही आश्वस्त हैं। उदाहरण के लिए, मान लीजिए कि आप रोबोटिक्स में एक स्नातक छात्र हैं, और एक ऐसा रोबोट बनाना चाहते हैं जो पिछले रोबोटों की तुलना में पैरों पर बेहतर ढंग से चलता हो। समाधान के पहले चरण में प्रेरणा का होना अनिवार्य है—यानी, ऐसी रचनात्मक सोच, जो इसी समस्या को हल करने में पिछले शोधकर्ताओं द्वारा किए गए प्रयासों में सुधार लाने का लक्ष्य रखे। आपकी शुरुआत होगी पिछले प्रयासों से, उन अन्य समस्याओं से जुड़े मौजूदा विचारों से जिनके संबंधित होने का आप अनुमान लगाते हैं, और प्रकृति में चलने वाले जीवों की बनावट से। यह सब मिलकर मौजूदा ज्ञान बनता है, जिसमें आप नए-नए तरीकों से फेरबदल और संयोजन करेंगे, और फिर उसे आलोचना और आगे के संशोधनों की कसौटी पर कसेंगे। अंततः आप अपने नए रोबोट के हार्डवेयर का एक डिज़ाइन तैयार कर लेंगे: उसके पैर, अपने लीवर, जोड़ों, टेंडनों और मोटरों समेत; उसका शरीर, जिसमें ऊर्जा स्रोत रहेगा; उसके संवेदी अंग, जिनके ज़रिए उसे वह फ़ीडबैक मिलेगा जो उन अंगों को प्रभावी ढंग से नियंत्रित करने में मदद करेगा; और आख़िर में, वह कंप्यूटर जो इस नियंत्रण को अंजाम देगा। इस डिज़ाइन में, कंप्यूटर के प्रोग्राम को छोड़कर, हर चीज़ को आपने चलने के उद्देश्य के लिए अपनी क्षमतानुसार सर्वोत्तम ढंग से ढाल लिया होगा।

उस प्रोग्राम का काम होगा ऐसी स्थितियों को पहचानना—जैसे कि रोबोट का संतुलन बिगड़ना या उसके रास्ते में कोई बाधा आना—और फिर उचित कार्रवाई तय करके उसे अंजाम देना। यही आपकी शोध परियोजना का सबसे मुश्किल हिस्सा है। कोई यह कैसे तय करे कि किसी बाधा से बाईं या दाईं ओर से बचना सबसे अच्छा है, या उस पर से छलाँग लगानी है, उसे ठोकर मारकर हटाना है, या फिर उसे नज़रअंदाज़ करना है? या कि उस पर पैर रखने से बचने के लिए क़दम लंबे करने हैं—या उसे पार न कर पाने योग्य मानकर लौट जाना है? और, इन सभी सूरतों में, कोई इन फ़ैसलों को हकीक़त में कैसे बदले—संवेदी अंगों से मिल रहे फ़ीडबैक के आधार पर लगातार बदलते हुए, मोटरों और गियरों तक अनगिनत संकेत भेजकर?

आप समस्या को उप-समस्याओं में तोड़ेंगे। एक दिए गए कोण से मुड़ना, किसी दूसरे कोण से मुड़ने जैसा ही है। इससे आप मुड़ने के लिए एक ऐसा सबरूटीन लिख पाएँगे जो मुड़ने से जुड़ी तमाम संभावित स्थितियों को सँभाल सके। एक बार यह बन गया, तो प्रोग्राम के बाकी हिस्सों को जब भी मुड़ने की ज़रूरत महसूस होगी, वे बस इसे ‘कॉल’ कर लेंगे; उन्हें यह जानने की ज़रूरत नहीं पड़ेगी कि मुड़ने की पेचीदा प्रक्रिया में असल में होता क्या है। जब आप ऐसी जितनी भी उप-समस्याओं को पहचानकर हल कर लेंगे, तब तक आप एक ऐसा कोड, यानी एक ऐसी भाषा, गढ़ चुके होंगे जो यह बताने के लिए पूरी तरह अनुकूलित होगी कि आपके रोबोट को कैसे चलना है। इस भाषा में किसी सबरूटीन को किया गया हर कॉल अपने-आप में एक निर्देश या आदेश होता है।

अब तक आपने जो कुछ भी किया, उसका ज़्यादातर हिस्सा ‘प्रेरणा’ के दायरे में आता है: उसके लिए रचनात्मक सोच की ज़रूरत थी। लेकिन अब परिश्रम की बारी है। एक बार जब आप हर उस चीज़ को स्वचालित कर लेते हैं जिसे करना आप जानते हैं, तो कोई भी अतिरिक्त क्षमता हासिल करने के लिए आपके पास किसी-न-किसी तरह के ‘ट्रायल एंड एरर’ का सहारा लेने के सिवा कोई चारा नहीं बचता। हालाँकि, अब आपके पास एक ऐसी भाषा का लाभ है जिसे आपने रोबोट को चलने का निर्देश देने के लिए ही ढाला है। तो आप एक ऐसे प्रोग्राम से शुरुआत कर सकते हैं जो उस भाषा में तो सरल हो, भले ही कंप्यूटर के बुनियादी निर्देशों के लिहाज़ से बेहद जटिल हो, और जिसका मतलब हो सकता है: ‘आगे चलो, और किसी बाधा से टकराओ तो रुक जाओ।’ फिर आप उस प्रोग्राम के साथ रोबोट चलाकर देख सकते हैं कि क्या होता है (या आप रोबोट का कंप्यूटर सिमुलेशन चला सकते हैं)। जब वह गिरता है या कुछ और अनचाहा होता है, तो आप अपनी बनाई हुई उसी उच्च-स्तरीय भाषा का इस्तेमाल करते हुए अपने प्रोग्राम में सुधार कर सकते हैं, ताकि उभरने वाली ख़ामियों को दूर किया जा सके। इस तरीक़े में प्रेरणा कम और मेहनत ज़्यादा लगेगी।

लेकिन आपके सामने एक और रास्ता है: आप परिश्रम का काम कंप्यूटर को सौंप सकते हैं, एक ऐसी चीज़ का उपयोग करके जिसे ‘एवोल्यूशनरी एल्गोरिदम’ कहते हैं। आप उसी कंप्यूटर सिमुलेशन का इस्तेमाल करके कई परीक्षण चलाते हैं, हर बार शुरुआती प्रोग्राम में थोड़ा-बहुत बेतरतीब फेरबदल करके। एल्गोरिदम हर नकली रोबोट को आपके द्वारा तय की गई कसौटियों की एक पूरी श्रृंखला पर स्वचालित रूप से परखता है—जैसे कि वह बिना गिरे कितनी दूर चल सकता है, या बाधाओं और ऊबड़-खाबड़ ज़मीन से कितनी अच्छी तरह निपटता है, वग़ैरह। हर दौर के अंत में, सबसे अच्छा प्रदर्शन करने वाले प्रोग्राम को रख लिया जाता है और बाकियों को छोड़ दिया जाता है। फिर उस चुने हुए प्रोग्राम के कई नए संस्करण बनाए जाते हैं, और यह प्रक्रिया दोहराई जाती है। इस ‘विकासवादी’ प्रक्रिया के हज़ारों चरण दोहराने के बाद, आप पाएँगे कि आपका रोबोट आपके तय मानदंडों पर काफ़ी अच्छा चल रहा है। अब आप अपनी शोध-पत्र लिख सकते हैं। आप न केवल यह दावा कर सकते हैं कि आपने एक ऐसा रोबोट बना लिया है जो ज़रूरी कुशलता से चलता है, बल्कि यह भी कि आपने कंप्यूटर पर ‘विकास’ को साकार कर दिखाया है।

ऐसा काम कई बार सफलतापूर्वक किया जा चुका है। यह एक उपयोगी तकनीक है। यह निश्चित रूप से फेरबदल और चयन के बारी-बारी से आने के अर्थ में ‘विकास’ ही है। लेकिन क्या यह ‘विकास’ की उस ज़्यादा महत्वपूर्ण परिभाषा पर खरा उतरता है, जिसका अर्थ है ज्ञान का सृजन? यह एक दिन ज़रूर हासिल होगा, पर मुझे शक है कि यह अब तक नहीं हुआ है, और मेरा शक उसी वजह से है जिस वजह से मुझे चैटबॉट के ज़रा भी बुद्धिमान होने पर शक है। वजह यह है कि उनकी क्षमताओं की एक कहीं ज़्यादा सीधी-सादी व्याख्या मौजूद है: प्रोग्रामर की खुद की रचनात्मकता।

‘कृत्रिम विकास’ के मामले में इस संभावना को ख़ारिज करना कि ज्ञान का सृजन प्रोग्रामर ने किया था, उसी तर्ज़ पर काम करता है जिस पर यह जाँचना कि कोई प्रोग्राम AI है या नहीं—लेकिन यह काम ज़्यादा मुश्किल है, क्योंकि ‘विकास’ द्वारा कथित तौर पर बनाए गए ज्ञान की मात्रा बहुत कम होती है। भले ही प्रोग्रामर आप ख़ुद हों, आप यह तय करने की हालत में नहीं होते कि ज्ञान की वह थोड़ी-सी मात्रा आपने रची थी या नहीं। एक तो, उस भाषा को डिज़ाइन करने में लगे कई महीनों के दौरान आपने जो ज्ञान उसमें पिरोया था, उसमें से कुछ की अपनी पहुँच होगी, क्योंकि उसने ज्यामिति, यांत्रिकी जैसे क्षेत्रों के कुछ सामान्य सत्यों को कूटबद्ध किया था। दूसरी बात, भाषा को डिज़ाइन करते समय आपके दिमाग़ में लगातार यह चल रहा था कि आख़िरकार इसका इस्तेमाल किस तरह की क्षमताएँ ज़ाहिर करने के लिए किया जाएगा।

ट्यूरिंग-टैस्ट का विचार हमें यह गुमान देता है कि अगर एक एलिज़ा प्रोग्राम को ढेरों रटे-रटाए जवाब दे दिए जाएँ, तो वह अपने-आप ज्ञान का सृजन करने लगेगा; कृत्रिम विकास का विचार हमें यह गुमान देता है कि अगर हमारे पास फेरबदल और चयन की प्रक्रिया है, तो अनुकूलन का विकास अपने-आप होने लगेगा। लेकिन ज़रूरी नहीं कि ऐसा ही हो। दोनों ही मामलों में, एक और संभावना यह है कि प्रोग्राम के चलने के दौरान कोई नया ज्ञान पैदा ही न हो; सारा ज्ञान प्रोग्रामर द्वारा उसे बनाते समय ही पैदा हुआ हो।

एक बात जो ऐसे प्रोजेक्टों में हमेशा होती दिखती है, वह यह है कि एक बार जब वे अपना तय लक्ष्य हासिल कर लेते हैं, तो ‘विकासवादी’ प्रोग्राम को अगर और आगे चलने दिया जाए, तो उसमें कोई और सुधार नहीं होता। यह ठीक वैसा ही है जैसा तब होता अगर सफल रोबोट में मौजूद सारा ज्ञान असल में प्रोग्रामर से ही आया होता। लेकिन यह कोई निर्णायक आलोचना नहीं है: जैविक विकास भी अक्सर ‘फ़िटनेस के स्थानीय शिखर’ पर पहुँचकर रुक जाता है। साथ ही, अपनी रहस्यमयी सार्वभौमिकता को पाने के बाद, कोई भी नया महत्वपूर्ण ज्ञान रचने से पहले वह भी क़रीब एक अरब साल तक ठहरा रहा। लेकिन फिर भी, ऐसे नतीजे पाना जिनका श्रेय किसी और चीज़ को भी दिया जा सकता हो, विकास का सबूत नहीं माना जा सकता।

इसीलिए मुझे शक है कि किसी भी ‘कृत्रिम विकास’ ने आज तक ज्ञान का सृजन किया है। और इन्हीं वजहों से, मेरी यही राय उस थोड़े अलग क़िस्म के ‘कृत्रिम विकास’ के बारे में भी है जो एक वर्चुअल माहौल में नकली जीव विकसित करने की कोशिश करता है, और उस क़िस्म के बारे में भी जो अलग-अलग वर्चुअल प्रजातियों को एक-दूसरे से भिड़ाता है।

इस बात को परखने के लिए, मैं एक ज़रा अलग तरह का प्रयोग देखना चाहूँगा: प्रोजेक्ट से स्नातक छात्र को हटा दीजिए। फिर, चलने के बेहतर तरीक़े विकसित करने के लिए बनाए गए रोबोट की जगह, एक ऐसा रोबोट लीजिए जो पहले से ही किसी असल काम में इस्तेमाल हो रहा हो और इत्तिफ़ाक़ से चलने में सक्षम भी हो। और फिर, चलने के बारे में अनुमान व्यक्त करने के लिए सबरूटीनों की एक ख़ास भाषा बनाने के बजाय, बस उसके मौजूदा माइक्रोप्रोसेसर में उसके मौजूदा प्रोग्राम की जगह बेतरतीब संख्याएँ डाल दीजिए। उत्परिवर्तन के लिए, उसी तरह की गड़बड़ियों का इस्तेमाल कीजिए जो ऐसे प्रोसेसर में वैसे भी होती रहती हैं (बस सिमुलेशन में आप उन्हें अपनी मर्ज़ी से जितनी बार चाहें, करवा सकते हैं)। इस सबका मक़सद इस संभावना को ही खत्म कर देना है कि सिस्टम के डिज़ाइन में मानव-ज्ञान का कोई अप्रत्यक्ष योगदान है, और उसकी पहुँच को ग़लती से विकास का नतीजा समझा जा रहा है। फिर, उस बदलते हुए सिस्टम के सिमुलेशन को सामान्य तरीक़े से चलाइए। जितने चाहें, उतने। अगर वह रोबोट कभी भी पहले से बेहतर चलने लगा, तो मैं ग़लत हूँ। और अगर उसके बाद भी वह सुधरता ही गया, तो मैं बहुत ज़्यादा ग़लत हूँ।

ऊपर बताए प्रयोग की एक ख़ासियत, जो कृत्रिम विकास के आम तरीक़ों में नहीं मिलती, यह है कि इसके काम करने के लिए, भाषा (यानी सबरूटीनों की संरचना) को भी उन अनुकूलनों के साथ-साथ विकसित होना होगा जिन्हें वह व्यक्त कर रही थी। जीवमंडल में, उस सार्वभौमिकता की छलांग से पहले यही हो रहा था, जिस छलांग ने आख़िरकार डीएनए के आनुवंशिक कोड को स्थापित किया। जैसा कि मैंने कहा, हो सकता है कि वे सारे पिछले आनुवंशिक कोड बस कुछ ही जीवों को कोड करने में सक्षम थे, जो सब आपस में काफ़ी मिलते-जुलते थे। और यह कि वह बेइंतहा समृद्ध जीवमंडल जो हम आज अपने चारों ओर देखते हैं—जो भाषा को जस-का-तस रखते हुए सिर्फ़ जीनों में बेतरतीब फेरबदल करके बना है—एक ऐसी चीज़ है जो उस छलांग के बाद ही मुमकिन हो पाई। हम तो यह भी नहीं जानते कि वहाँ किस तरह की सार्वभौमिकता पैदा हुई थी। तो फिर हम यह उम्मीद क्यों करें कि हमारा कृत्रिम विकास उसके बिना काम कर जाएगा?

मुझे लगता है कि हमें इस सच को स्वीकारना होगा, कृत्रिम विकास और AI दोनों के मामले में, कि ये बहुत कठिन समस्याएँ हैं। प्रकृति में ये चीज़ें कैसे हासिल हुईं, इसमें आज भी गंभीर अनसुलझे पहलू हैं। उन अनसुलझे पहलुओं को खोजे बिना ही उन्हें कृत्रिम रूप से बनाने की कोशिश करना शायद एक आज़माने लायक़ विचार था। लेकिन इसमें कोई हैरानी नहीं होनी चाहिए कि यह नाकाम रहा। ख़ास तौर पर, हम यह नहीं जानते कि डीएनए कोड, जो बैक्टीरिया का वर्णन करने के लिए विकसित हुआ था, उसमें डायनासोर और इंसानों तक का वर्णन करने की पहुँच कहाँ से आई। और, हालाँकि यह साफ़ लगता है कि एक AI में क्वालिया और चेतना होंगे, हम इन चीज़ों की व्याख्या नहीं कर सकते। जब तक हम इनकी व्याख्या नहीं कर सकते, हम उन्हें किसी कंप्यूटर प्रोग्राम में उतारने की उम्मीद कैसे कर सकते हैं? या वे किसी और लक्ष्य के लिए बनाए गए प्रोजेक्टों से अनायास ही क्यों उभर आएँगी? लेकिन मेरा अंदाज़ा है कि जिस दिन हम इन्हें समझ लेंगे, उस दिन विकास, बुद्धिमत्ता और उससे जुड़ी तमाम विशेषताओं के नक्षत्र को कृत्रिम रूप से साकार करना कोई बहुत बड़ा काम नहीं होगा।